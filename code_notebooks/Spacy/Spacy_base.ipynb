{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "id": "Dj7XmJ1ifKMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "p2Vj7mNNa1fT"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from spacy.tokens import DocBin\n",
        "import spacy\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train=pd.read_csv('final_train.csv', encoding='utf-8', encoding_errors='ignore')\n",
        "df_train.columns=['sentence','tags']\n",
        "\n",
        "df_test=pd.read_csv('final_test.csv', encoding='utf-8', encoding_errors='ignore')\n",
        "df_test.columns=['sentence','tags']"
      ],
      "metadata": {
        "id": "njiO90kka2Nk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to obtain entity format according to Spacy\n",
        "def get_entity_tuple(df):\n",
        "  list_of_entities = []\n",
        "  for x in range(len(df)):\n",
        "    d = {\"entities\": []}\n",
        "    i, j = 0, 0\n",
        "    idx = -1\n",
        "    \n",
        "    tokens = df[\"tags\"][x].split()\n",
        "    words = df['sentence'][x].split()\n",
        "    if len(words) != len(tokens):\n",
        "      continue\n",
        "\n",
        "    temp = df[\"sentence\"][x] + \" \"\n",
        "    for char in temp:\n",
        "      if char == \" \":\n",
        "        d[\"entities\"].append((i, j, tokens[idx]))\n",
        "        j += 1\n",
        "        i = j\n",
        "        idx += 1\n",
        "      else:\n",
        "        j += 1\n",
        "    list_of_entities.append((df[\"sentence\"][x], d))\n",
        "  \n",
        "  return list_of_entities"
      ],
      "metadata": {
        "id": "L4Ds7dhfdne4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# apply on train and test set\n",
        "train_entities = get_entity_tuple(df_train)\n",
        "test_entities = get_entity_tuple(df_test)"
      ],
      "metadata": {
        "id": "y99N2skBdpao"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "db = DocBin()\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "for text, annot in tqdm(train_entities): # data in previous format\n",
        "    doc = nlp.make_doc(text) # create doc object from text\n",
        "    ents = []\n",
        "    for start, end, label in annot[\"entities\"]: # add character indexes\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "        if span is None:\n",
        "            print(\"Skipping entity\")\n",
        "        else:\n",
        "            ents.append(span)\n",
        "    doc.ents = ents # label the text with the ents\n",
        "    db.add(doc)\n",
        "    \n",
        "db.to_disk(\"./train.spacy\") # save the docbin object"
      ],
      "metadata": {
        "id": "IPs-8bxUdq3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "db = DocBin()\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "for text, annot in tqdm(test_entities): # data in previous format\n",
        "    doc = nlp.make_doc(text) # create doc object from text\n",
        "    ents = []\n",
        "    for start, end, label in annot[\"entities\"]: # add character indexes\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "        if span is None:\n",
        "            print(\"Skipping entity\")\n",
        "        else:\n",
        "            ents.append(span)\n",
        "    doc.ents = ents # label the text with the ents\n",
        "    db.add(doc)\n",
        "    \n",
        "db.to_disk(\"./test.spacy\") # save the docbin object"
      ],
      "metadata": {
        "id": "heGgyNW0dt6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "PThBGObieu24"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy init fill-config base_config.cfg config.cfg"
      ],
      "metadata": {
        "id": "2fSB1BKAdvnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./test.spacy"
      ],
      "metadata": {
        "id": "M7NA8PnndwJw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
