{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_trf"
      ],
      "metadata": {
        "id": "ATIX4bzKp6e_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy-transformers\n"
      ],
      "metadata": {
        "id": "OODg6xUmq55F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "qEFNi4WtqY1p"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wmnfnkYqnjVZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from spacy.tokens import DocBin\n",
        "import spacy\n",
        "from tqdm import tqdm\n",
        "import spacy_transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train=pd.read_csv('final_train.csv', encoding='utf-8', encoding_errors='ignore')\n",
        "df_train.columns=['sentence','tags']\n",
        "\n",
        "df_test=pd.read_csv('final_test.csv', encoding='utf-8', encoding_errors='ignore')\n",
        "df_test.columns=['sentence','tags']"
      ],
      "metadata": {
        "id": "5LuYvgdfolLf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to obtain entity format according to Spacy\n",
        "def get_entity_tuple(df):\n",
        "  list_of_entities = []\n",
        "  for x in range(len(df)):\n",
        "    d = {\"entities\": []}\n",
        "    i, j = 0, 0\n",
        "    idx = -1\n",
        "    \n",
        "    tokens = df[\"tags\"][x].split()\n",
        "    words = df['sentence'][x].split()\n",
        "    if len(words) != len(tokens):\n",
        "      continue\n",
        "\n",
        "    temp = df[\"sentence\"][x] + \" \"\n",
        "    for char in temp:\n",
        "      if char == \" \":\n",
        "        d[\"entities\"].append((i, j, tokens[idx]))\n",
        "        j += 1\n",
        "        i = j\n",
        "        idx += 1\n",
        "      else:\n",
        "        j += 1\n",
        "    list_of_entities.append((df[\"sentence\"][x], d))\n",
        "  \n",
        "  return list_of_entities"
      ],
      "metadata": {
        "id": "UyAaCYN8otIS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply on train and test set\n",
        "train_entities = get_entity_tuple(df_train)\n",
        "test_entities = get_entity_tuple(df_test)"
      ],
      "metadata": {
        "id": "eDKWpqo3owDu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = DocBin()\n",
        "nlp = spacy.load(\"en_core_web_trf\")\n",
        "\n",
        "for text, annot in tqdm(train_entities): # data in previous format\n",
        "    doc = nlp.make_doc(text) # create doc object from text\n",
        "    ents = []\n",
        "    for start, end, label in annot[\"entities\"]: # add character indexes\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "        if span is None:\n",
        "            print(\"Skipping entity\")\n",
        "        else:\n",
        "            ents.append(span)\n",
        "    doc.ents = ents # label the text with the ents\n",
        "    db.add(doc)\n",
        "    \n",
        "db.to_disk(\"./train.spacy\") # save the docbin object\n"
      ],
      "metadata": {
        "id": "qqe7IS9OoymG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = DocBin()\n",
        "nlp = spacy.load(\"en_core_web_trf\")\n",
        "\n",
        "for text, annot in tqdm(test_entities): # data in previous format\n",
        "    doc = nlp.make_doc(text) # create doc object from text\n",
        "    ents = []\n",
        "    for start, end, label in annot[\"entities\"]: # add character indexes\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "        if span is None:\n",
        "            print(\"Skipping entity\")\n",
        "        else:\n",
        "            ents.append(span)\n",
        "    doc.ents = ents # label the text with the ents\n",
        "    db.add(doc)\n",
        "    \n",
        "db.to_disk(\"./test.spacy\") # save the docbin object"
      ],
      "metadata": {
        "id": "AgRaogEXo2_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "!python -m spacy train config_trf.cfg --output ./output --paths.train ./train.spacy --paths.dev ./test.spacy --gpu-id 0"
      ],
      "metadata": {
        "id": "pGBcBvjJo38G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}